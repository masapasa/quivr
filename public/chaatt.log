"quivr/backend/parsers/docx.py" ```from fastapi import UploadFile
from langchain.document_loaders import Docx2txtLoader

from .common import process_file


def process_docx(file: UploadFile, enable_summarization, user):
    return process_file(file, Docx2txtLoader, ".docx", enable_summarization, user)
```
"quivr/backend/parsers/html.py" ```import os
import re
import tempfile
import unicodedata

import requests
from fastapi import UploadFile
from langchain.document_loaders import UnstructuredHTMLLoader

from .common import process_file
def process_html(file: UploadFile, enable_summarization, user):
    return process_file(file, UnstructuredHTMLLoader, ".html", enable_summarization, user)
def get_html(url):
    response = requests.get(url)
    if response.status_code == 200:
        return response.text
    else:
        return None
def slugify(text):
    text = unicodedata.normalize('NFKD', text).encode(
        'ascii', 'ignore').decode('utf-8')
    text = re.sub(r'[^\w\s-]', '', text).strip().lower()
    text = re.sub(r'[-\s]+', '-', text)
    return text
```
"quivr/backend/parsers/txt.py" ```from fastapi import UploadFile
from langchain.document_loaders import TextLoader

from .common import process_file


async def process_txt(file: UploadFile, enable_summarization, user):
    return await process_file(file, TextLoader, ".txt", enable_summarization, user)
```
"quivr/backend/parsers/odt.py" ```from fastapi import UploadFile
from langchain.document_loaders import UnstructuredODTLoader

from .common import process_file


def process_odt(file: UploadFile, enable_summarization, user):
    return process_file(file, UnstructuredODTLoader, ".odt", enable_summarization, user)
```
"quivr/backend/parsers/pdf.py" ```from fastapi import UploadFile
from langchain.document_loaders import PyPDFLoader

from .common import process_file


def process_pdf(file: UploadFile, enable_summarization, user):
    return process_file(file, PyPDFLoader, ".pdf", enable_summarization, user)
```
"quivr/backend/parsers/powerpoint.py" ```from fastapi import UploadFile
from langchain.document_loaders import UnstructuredPowerPointLoader

from .common import process_file


def process_powerpoint(file: UploadFile, enable_summarization, user):
    return process_file(file, UnstructuredPowerPointLoader, ".pptx", enable_summarization, user)
```
"quivr/backend/parsers/common.py" ```# from stats import add_usage
import asyncio
import os
import tempfile
import time
from typing import Optional

from fastapi import UploadFile
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from utils.file import compute_sha1_from_content, compute_sha1_from_file
from utils.vectors import create_summary, create_vector, documents_vector_store


async def process_file(file: UploadFile, loader_class, file_suffix, enable_summarization, user):
    documents = []
    file_name = file.filename
    file_size = file.file._file.tell()  # Getting the size of the file
    dateshort = time.strftime("%Y%m%d")

    # Here, we're writing the uploaded file to a temporary file, so we can use it with your existing code.
    with tempfile.NamedTemporaryFile(delete=False, suffix=file.filename) as tmp_file:
        await file.seek(0)
        content = await file.read()
        tmp_file.write(content)
        tmp_file.flush()

        loader = loader_class(tmp_file.name)
        documents = loader.load()
        # Ensure this function works with FastAPI
        file_sha1 = compute_sha1_from_file(tmp_file.name)

    os.remove(tmp_file.name)
    chunk_size = 500
    chunk_overlap = 0

    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=chunk_size, chunk_overlap=chunk_overlap)

    documents = text_splitter.split_documents(documents)

    for doc in documents:
        metadata = {
            "file_sha1": file_sha1,
            "file_size": file_size,
            "file_name": file_name,
            "chunk_size": chunk_size,
            "chunk_overlap": chunk_overlap,
            "date": dateshort,
            "summarization": "true" if enable_summarization else "false"
        }
        doc_with_metadata = Document(
            page_content=doc.page_content, metadata=metadata)
        create_vector(user.email, doc_with_metadata)
            #     add_usage(stats_db, "embedding", "audio", metadata={"file_name": file_meta_name,"file_type": ".txt", "chunk_size": chunk_size, "chunk_overlap": chunk_overlap})

        if enable_summarization and ids and len(ids) > 0:
            create_summary(ids[0], doc.page_content, metadata)
    return


async def file_already_exists(supabase, file, user):
    file_content = await file.read()
    file_sha1 = compute_sha1_from_content(file_content)
    response = supabase.table("vectors").select("id").filter("metadata->>file_sha1", "eq", file_sha1) \
        .filter("user_id", "eq", user.email).execute()
    return len(response.data) > 0
```
"quivr/backend/parsers/markdown.py" ```from fastapi import UploadFile
from langchain.document_loaders import UnstructuredMarkdownLoader

from .common import process_file


def process_markdown(file: UploadFile, enable_summarization, user):
    return process_file(file, UnstructuredMarkdownLoader, ".md", enable_summarization, user)
```
"quivr/backend/parsers/csv.py" ```from fastapi import UploadFile
from langchain.document_loaders.csv_loader import CSVLoader

from .common import process_file


def process_csv(file: UploadFile, enable_summarization, user):
    return process_file(file, CSVLoader, ".csv", enable_summarization, user)
```
"quivr/backend/parsers/audio.py" ```import os
import tempfile
import time
from io import BytesIO
from tempfile import NamedTemporaryFile

import openai
from fastapi import UploadFile
from langchain.document_loaders import TextLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from utils.file import compute_sha1_from_content
from utils.vectors import documents_vector_store

# # Create a function to transcribe audio using Whisper
# def _transcribe_audio(api_key, audio_file, stats_db):
#     openai.api_key = api_key
#     transcript = ""

#     with BytesIO(audio_file.read()) as audio_bytes:
#         # Get the extension of the uploaded file
#         file_extension = os.path.splitext(audio_file.name)[-1]

#         # Create a temporary file with the uploaded audio data and the correct extension
#         with tempfile.NamedTemporaryFile(delete=True, suffix=file_extension) as temp_audio_file:
#             temp_audio_file.write(audio_bytes.read())
#             temp_audio_file.seek(0)  # Move the file pointer to the beginning of the file

#             transcript = openai.Audio.translate("whisper-1", temp_audio_file)

#     return transcript

# async def process_audio(upload_file: UploadFile, stats_db):
async def process_audio(upload_file: UploadFile, enable_summarization: bool, user):

    file_sha = ""
    dateshort = time.strftime("%Y%m%d-%H%M%S")
    file_meta_name = f"audiotranscript_{dateshort}.txt"
    # uploaded file to file object

    openai_api_key = os.environ.get("OPENAI_API_KEY")

    # Here, we're writing the uploaded file to a temporary file, so we can use it with your existing code.
    with tempfile.NamedTemporaryFile(delete=False, suffix=upload_file.filename) as tmp_file:
        await upload_file.seek(0)
        content = await upload_file.read()
        tmp_file.write(content)
        tmp_file.flush()
        tmp_file.close()

        with open(tmp_file.name, "rb") as audio_file:
            transcript = openai.Audio.transcribe("whisper-1", audio_file)

    file_sha = compute_sha1_from_content(transcript.text.encode("utf-8"))
    file_size = len(transcript.text.encode("utf-8"))

    # Load chunk size and overlap from sidebar
    chunk_size = 500
    chunk_overlap = 0

    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    texts = text_splitter.split_text(transcript)

    docs_with_metadata = [Document(page_content=text, metadata={"file_sha1": file_sha, "file_size": file_size, "file_name": file_meta_name,
                                   "chunk_size": chunk_size, "chunk_overlap": chunk_overlap, "date": dateshort}) for text in texts]

    # if st.secrets.self_hosted == "false":
    #     add_usage(stats_db, "embedding", "audio", metadata={"file_name": file_meta_name,"file_type": ".txt", "chunk_size": chunk_size, "chunk_overlap": chunk_overlap})
    documents_vector_store.add_documents(docs_with_metadata)

    return documents_vector_store
```
"quivr/backend/parsers/notebook.py" ```from fastapi import UploadFile
from langchain.document_loaders import NotebookLoader

from .common import process_file


def process_ipnyb(file: UploadFile, enable_summarization, user):
    return process_file(file, NotebookLoader, "ipynb", enable_summarization, user)
```
"quivr/backend/parsers/epub.py" ```from fastapi import UploadFile
from langchain.document_loaders.epub import UnstructuredEPubLoader

from .common import process_file


def process_epub(file: UploadFile, enable_summarization, user):
    return process_file(file, UnstructuredEPubLoader, ".epub", enable_summarization, user)
```. file_already_exists uses supabase.table("vectors"). But i would like to upload the file to supabase storage.once the file us uploaded,
the embedding of the content is also uploaded to the supabase vector table. give me complete correct modified code based on the code i have provided
to upload the file to supabase storage

INFO:     127.0.0.1:57720 - "POST /upload HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "quivr/.venv/lib/python3.11/site-packages/uvicorn/protocols/http/h11_impl.py", line 428, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "quivr/.venv/lib/python3.11/site-packages/uvicorn/middleware/proxy_headers.py", line 78, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "quivr/.venv/lib/python3.11/site-packages/fastapi/applications.py", line 276, in __call__
    await super().__call__(scope, receive, send)
  File "quivr/.venv/lib/python3.11/site-packages/starlette/applications.py", line 122, in __call__
    await self.middleware_stack(scope, receive, send)
  File "quivr/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py", line 184, in __call__
    raise exc
  File "quivr/.venv/lib/python3.11/site-packages/starlette/middleware/errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "quivr/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py", line 91, in __call__
    await self.simple_response(scope, receive, send, request_headers=headers)
  File "quivr/.venv/lib/python3.11/site-packages/starlette/middleware/cors.py", line 146, in simple_response
    await self.app(scope, receive, send)
  File "quivr/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 79, in __call__
    raise exc
  File "quivr/.venv/lib/python3.11/site-packages/starlette/middleware/exceptions.py", line 68, in __call__
    await self.app(scope, receive, sender)
  File "quivr/.venv/lib/python3.11/site-packages/fastapi/middleware/asyncexitstack.py", line 21, in __call__
    raise e
  File "quivr/.venv/lib/python3.11/site-packages/fastapi/middleware/asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "quivr/.venv/lib/python3.11/site-packages/starlette/routing.py", line 718, in __call__
    await route.handle(scope, receive, send)
  File "quivr/.venv/lib/python3.11/site-packages/starlette/routing.py", line 276, in handle
    await self.app(scope, receive, send)
  File "quivr/.venv/lib/python3.11/site-packages/starlette/routing.py", line 66, in app
    response = await func(request)
               ^^^^^^^^^^^^^^^^^^^
  File "quivr/.venv/lib/python3.11/site-packages/fastapi/routing.py", line 237, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "quivr/.venv/lib/python3.11/site-packages/fastapi/routing.py", line 163, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "quivr/backend/main.py", line 63, in upload_file
    message = await filter_file(file, enable_summarization, commons['supabase'], user)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "quivr/backend/utils/processors.py", line 51, in filter_file
    await file_processors[file_extension](file, enable_summarization, user)
  File "quivr/backend/parsers/common.py", line 34, in process_file
    result = supabase.from_('nubri').upload(file_name, tmp_file)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "quivr/.venv/lib/python3.11/site-packages/storage3/_sync/file_api.py", line 228, in upload
    files = {"file": (filename, open(file, "rb"), headers.pop("content-type"))}
                                ^^^^^^^^^^^^^^^^
TypeError: expected str, bytes or os.PathLike object, not _TemporaryFileWrapper